{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "KVcLJT6jXqdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "aAx2Mf3DFpQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLe05yXv7jQO",
        "outputId": "952118ba-071f-4b1d-f11a-4f21f9e81b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uniseg\n",
            "  Downloading uniseg-0.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading uniseg-0.10.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: uniseg\n",
            "Successfully installed uniseg-0.10.0\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Imports\n",
        "'''\n",
        "!pip install uniseg\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import shutil\n",
        "#HTMl library to generate the connectivity html file\n",
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfr4kTIE7wop",
        "outputId": "fb54a893-24c7-4cf8-df87-91bbc1e59e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1915M  100 1915M    0     0   123M      0  0:00:15  0:00:15 --:--:--  137M\n",
            "dakshina_dataset_v1.0/bn/\n",
            "dakshina_dataset_v1.0/bn/lexicons/\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/romanized/\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/gu/\n",
            "dakshina_dataset_v1.0/gu/lexicons/\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/romanized/\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/hi/\n",
            "dakshina_dataset_v1.0/hi/lexicons/\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/hi/romanized/\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/kn/\n",
            "dakshina_dataset_v1.0/kn/lexicons/\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/kn/romanized/\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ml/\n",
            "dakshina_dataset_v1.0/ml/lexicons/\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/tmp.rom.txt\n",
            "dakshina_dataset_v1.0/ml/lexicons/tmp.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/romanized/\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/mr/\n",
            "dakshina_dataset_v1.0/mr/lexicons/\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/romanized/\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/pa/\n",
            "dakshina_dataset_v1.0/pa/lexicons/\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/pa/romanized/\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/sd/\n",
            "dakshina_dataset_v1.0/sd/lexicons/\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/sd/romanized/\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/si/\n",
            "dakshina_dataset_v1.0/si/lexicons/\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/romanized/\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ta/\n",
            "dakshina_dataset_v1.0/ta/lexicons/\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/romanized/\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/te/\n",
            "dakshina_dataset_v1.0/te/lexicons/\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/romanized/\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ur/\n",
            "dakshina_dataset_v1.0/ur/lexicons/\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/romanized/\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/README.md\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Downloading the dataset\n",
        "'''\n",
        "# Download the dataset\n",
        "!curl https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar --output daksh.tar\n",
        "# Extract the downloaded tar file\n",
        "!tar -xvf  'daksh.tar'\n",
        "# Set the file paths to train, validation and test dataset\n",
        "#train_path\n",
        "train_file_path=os.path.join(os.getcwd(),\"dakshina_dataset_v1.0\",\"hi\",\"lexicons\",\"hi.translit.sampled.train.tsv\")\n",
        "#validation_path\n",
        "vaildation_file_path = os.path.join(os.getcwd(),\"dakshina_dataset_v1.0\",\"hi\",\"lexicons\",\"hi.translit.sampled.dev.tsv\")\n",
        "#test_path\n",
        "test_file_path = os.path.join(os.getcwd(),\"dakshina_dataset_v1.0\",\"hi\",\"lexicons\",\"hi.translit.sampled.test.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔤 Character-Level Word Preprocessing Pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "w_hMcGep5bNd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TqZUg_I-81Sh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Preprocesses a word by adding start and end characters.\n",
        "'''\n",
        "def word_process(word):\n",
        "  word = '\\t' + word + '\\n'\n",
        "  return word\n",
        "\n",
        "'''\n",
        "Reads lines from a file and returns them as a list.\n",
        "'''\n",
        "def read_lines(path):\n",
        "  file = io.open(path, encoding='UTF-8')\n",
        "  text = file.read()\n",
        "  lines = text.strip().split('\\n')\n",
        "  return lines\n",
        "\n",
        "'''\n",
        "Processes a line and returns a list of processed words.\n",
        "'''\n",
        "def process_line(line):\n",
        "  parts = line.split('\\t')\n",
        "  new_parts = []\n",
        "  # Skip the last part (usually empty or label)\n",
        "  for i in range(len(parts) - 1):\n",
        "    processed_word = word_process(parts[i])\n",
        "    new_parts.append(processed_word)\n",
        "  return new_parts\n",
        "\n",
        "'''\n",
        "Creates pairs of target and input words.\n",
        "'''\n",
        "def create_dataset(path):\n",
        "  lines = read_lines(path)\n",
        "  all_pairs = []\n",
        "  for line in lines[:-1]:\n",
        "    pair = process_line(line)\n",
        "    all_pairs.append(pair)\n",
        "\n",
        "  input_words = []\n",
        "  target_words = []\n",
        "\n",
        "  for pair in all_pairs:\n",
        "    target_words.append(pair[0])\n",
        "    input_words.append(pair[1])\n",
        "\n",
        "  return input_words, target_words\n",
        "\n",
        "'''\n",
        "Creates a character-level tokenizer.\n",
        "'''\n",
        "def build_tokenizer():\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\n",
        "  return tokenizer\n",
        "\n",
        "'''\n",
        "Tokenizes and pads the given list of words.\n",
        "'''\n",
        "def tokenize(lang):\n",
        "  tokenizer = build_tokenizer()\n",
        "  tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  sequences = tokenizer.texts_to_sequences(lang)\n",
        "  padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "\n",
        "  return padded_sequences, tokenizer\n",
        "\n",
        "'''\n",
        "Loads the dataset, returning tokenized and padded input/output tensors and their tokenizers.\n",
        "'''\n",
        "def load_dataset(path):\n",
        "  input_lang, output_lang = create_dataset(path)\n",
        "\n",
        "  input_tensor, input_tokenizer = tokenize(input_lang)\n",
        "  output_tensor, output_tokenizer = tokenize(output_lang)\n",
        "\n",
        "  return input_tensor, output_tensor, input_tokenizer, output_tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Training Dataset\n",
        "\n",
        "This section reads the full training dataset using the `load_dataset` function defined earlier. It also calculates the maximum sequence lengths of the input and target tensors, which are useful for building the model.\n"
      ],
      "metadata": {
        "id": "SUrtdLNp5URM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mTTPBoWe8j-x"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Reading the training dataset entirely\n",
        "'''\n",
        "# Use the entire training dataset file\n",
        "input_tensor_train, target_tensor_train, inp_lang, targ_lang = load_dataset(train_file_path)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor_train.shape[1], input_tensor_train.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence Encoder Classes\n",
        "Defines TensorFlow-based encoder classes for sequence models using GRU, LSTM, and Simple RNN layers. Each class includes an embedding layer, the recurrent layer, and hidden state initialization.\n",
        "\n"
      ],
      "metadata": {
        "id": "CXU1boLA6Sra"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9aU5v5A68Raa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "'''\n",
        "Class - GRU Encoder\n",
        "'''\n",
        "class GRU_Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, dropout=0):\n",
        "    super(GRU_Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = self.create_embedding_layer(vocab_size, embedding_dim)\n",
        "    self.gru = self.create_gru_layer(enc_units, dropout)\n",
        "\n",
        "  # Create embedding layer\n",
        "  def create_embedding_layer(self, vocab_size, embedding_dim):\n",
        "    return tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "  # Create GRU layer\n",
        "  def create_gru_layer(self, units, dropout):\n",
        "    return tf.keras.layers.GRU(\n",
        "      units,\n",
        "      return_sequences=True,\n",
        "      return_state=True,\n",
        "      recurrent_initializer='glorot_uniform',\n",
        "      dropout=dropout\n",
        "    )\n",
        "\n",
        "  # Forward pass through the encoder\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  # Initialize hidden state to zeros\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "\n",
        "'''\n",
        "Class - LSTM Encoder\n",
        "'''\n",
        "class LSTM_Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, dropout=0):\n",
        "    super(LSTM_Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = self.create_embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = self.create_lstm(enc_units, dropout)\n",
        "\n",
        "  # Embedding layer\n",
        "  def create_embedding(self, vocab_size, embedding_dim):\n",
        "    return tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "  # LSTM layer\n",
        "  def create_lstm(self, units, dropout):\n",
        "    return tf.keras.layers.LSTM(\n",
        "      units,\n",
        "      return_sequences=True,\n",
        "      return_state=True,\n",
        "      recurrent_initializer='glorot_uniform',\n",
        "      dropout=dropout\n",
        "    )\n",
        "\n",
        "  # Forward pass through the LSTM encoder\n",
        "  def call(self, x, hidden, cell_state):\n",
        "    x = self.embedding(x)\n",
        "    output, h_state, c_state = self.lstm(x, initial_state=[hidden, cell_state])\n",
        "    return output, h_state, c_state\n",
        "\n",
        "  # Initialize both hidden and cell state\n",
        "  def initialize_hidden_state(self):\n",
        "    hidden = tf.zeros((self.batch_sz, self.enc_units))\n",
        "    cell = tf.zeros((self.batch_sz, self.enc_units))\n",
        "    return hidden, cell\n",
        "\n",
        "\n",
        "'''\n",
        "Class - Simple RNN Encoder\n",
        "'''\n",
        "class RNN_Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, dropout=0):\n",
        "    super(RNN_Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = self.init_embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = self.init_rnn(enc_units, dropout)\n",
        "\n",
        "  # Set up embedding\n",
        "  def init_embedding(self, vocab_size, embedding_dim):\n",
        "    return tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "  # Set up RNN\n",
        "  def init_rnn(self, units, dropout):\n",
        "    return tf.keras.layers.SimpleRNN(\n",
        "      units,\n",
        "      return_sequences=True,\n",
        "      return_state=True,\n",
        "      recurrent_initializer='glorot_uniform',\n",
        "      dropout=dropout\n",
        "    )\n",
        "\n",
        "  # Forward pass\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, final_state = self.rnn(x, initial_state=hidden)\n",
        "    return output, final_state\n",
        "\n",
        "  # Hidden state initialization\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C3C9skWL8-If"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Attention class (Bhadanau Attention) refernce for the attention  - https://arxiv.org/abs/1409.0473\n",
        "'''\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  #initialization\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)  #W_1\n",
        "    self.W2 = tf.keras.layers.Dense(units)  #W_2\n",
        "    self.V = tf.keras.layers.Dense(1)       #V\n",
        "\n",
        "  '''\n",
        "  call function genrating the context vector and the attention weights\n",
        "  '''\n",
        "  def call(self, query, values):\n",
        "    '''\n",
        "    shape of query hidden state == (batch_size, hidden size)\n",
        "    shape of query_with_time_axis == (batch_size, 1, hidden size)\n",
        "    shape of values  == (batch_size, max_len, hidden size)\n",
        "    '''\n",
        "    #To broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # shape of score == (batch_size, max_length, 1)\n",
        "    # shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # shape of attention_weights == (batch_size, max_length, 1)\n",
        "    #generating the attention weights\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    #generating the context vector\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    #returning the context vector and the attention weights\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder Classes\n",
        "\n",
        "Refactored TensorFlow decoders with attention for seq2seq tasks.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rTp09sdo617E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Snk7YcBD9AQy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "GRU Decoder Implementation - Refactored\n",
        "'''\n",
        "class GRU_Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, dropout=0):\n",
        "        super(GRU_Decoder, self).__init__()\n",
        "        # Store configuration parameters\n",
        "        self.batch_size = batch_sz\n",
        "        self.decoder_units = dec_units\n",
        "        self.vocabulary_size = vocab_size\n",
        "        self.embed_dimensions = embedding_dim\n",
        "\n",
        "        # Initialize all layers in __init__ to avoid variable creation issues\n",
        "        self.word_embeddings = tf.keras.layers.Embedding(\n",
        "            input_dim=self.vocabulary_size,\n",
        "            output_dim=self.embed_dimensions\n",
        "        )\n",
        "\n",
        "        self.gru_cell = tf.keras.layers.GRU(\n",
        "            units=self.decoder_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.output_projection = tf.keras.layers.Dense(units=self.vocabulary_size)\n",
        "        self.attention_layer = BahdanauAttention(self.decoder_units)\n",
        "\n",
        "    def _compute_context_vector(self, current_hidden, encoder_outputs):\n",
        "        \"\"\"Extract attention context and weights\"\"\"\n",
        "        context_vec, attn_weights = self.attention_layer(current_hidden, encoder_outputs)\n",
        "        return context_vec, attn_weights\n",
        "\n",
        "    def _prepare_input_sequence(self, input_tokens, context_vector):\n",
        "        \"\"\"Process input tokens and concatenate with context\"\"\"\n",
        "        # Step 1: Convert tokens to embeddings\n",
        "        embedded_input = self.word_embeddings(input_tokens)\n",
        "\n",
        "        # Step 2: Expand context vector dimensions\n",
        "        expanded_context = tf.expand_dims(context_vector, axis=1)\n",
        "\n",
        "        # Step 3: Concatenate context and embeddings\n",
        "        combined_input = tf.concat([expanded_context, embedded_input], axis=-1)\n",
        "        return combined_input\n",
        "\n",
        "    def _transform_gru_output(self, gru_output):\n",
        "        \"\"\"Transform GRU output to final predictions\"\"\"\n",
        "        # Reshape for dense layer\n",
        "        reshaped_output = tf.reshape(gru_output, (-1, gru_output.shape[2]))\n",
        "\n",
        "        # Generate predictions\n",
        "        predictions = self.output_projection(reshaped_output)\n",
        "        return predictions\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        \"\"\"Main forward pass computation\"\"\"\n",
        "        # Phase 1: Compute attention mechanism\n",
        "        context_vector, attention_weights = self._compute_context_vector(hidden, enc_output)\n",
        "\n",
        "        # Phase 2: Prepare decoder input\n",
        "        decoder_input = self._prepare_input_sequence(x, context_vector)\n",
        "\n",
        "        # Phase 3: Process through GRU\n",
        "        gru_output, new_state = self.gru_cell(decoder_input)\n",
        "\n",
        "        # Phase 4: Generate final output\n",
        "        final_output = self._transform_gru_output(gru_output)\n",
        "\n",
        "        return final_output, new_state, attention_weights\n",
        "\n",
        "\n",
        "'''\n",
        "LSTM Decoder Implementation - Refactored\n",
        "'''\n",
        "class LSTM_Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, dropout=0):\n",
        "        super(LSTM_Decoder, self).__init__()\n",
        "        # Configuration storage\n",
        "        self.batch_size = batch_sz\n",
        "        self.decoder_units = dec_units\n",
        "        self.vocab_length = vocab_size\n",
        "        self.embedding_size = embedding_dim\n",
        "\n",
        "        # Initialize all components in __init__\n",
        "        self.token_embeddings = tf.keras.layers.Embedding(\n",
        "            self.vocab_length,\n",
        "            self.embedding_size\n",
        "        )\n",
        "\n",
        "        self.lstm_unit = tf.keras.layers.LSTM(\n",
        "            self.decoder_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.prediction_layer = tf.keras.layers.Dense(self.vocab_length)\n",
        "        self.attention_mechanism = BahdanauAttention(self.decoder_units)\n",
        "\n",
        "    def _extract_attention_context(self, hidden_state, encoder_sequence):\n",
        "        \"\"\"Compute attention context and weights\"\"\"\n",
        "        attention_context, weights = self.attention_mechanism(hidden_state, encoder_sequence)\n",
        "        return attention_context, weights\n",
        "\n",
        "    def _combine_context_with_input(self, input_sequence, attention_context):\n",
        "        \"\"\"Combine attention context with input embeddings\"\"\"\n",
        "        # Transform input to embeddings\n",
        "        embedded_tokens = self.token_embeddings(input_sequence)\n",
        "\n",
        "        # Prepare context for concatenation\n",
        "        reshaped_context = tf.expand_dims(attention_context, 1)\n",
        "\n",
        "        # Merge information streams\n",
        "        merged_input = tf.concat([reshaped_context, embedded_tokens], axis=-1)\n",
        "        return merged_input\n",
        "\n",
        "    def _process_lstm_forward(self, lstm_input, hidden_state, cell_state):\n",
        "        \"\"\"Execute LSTM forward computation\"\"\"\n",
        "        initial_states = [hidden_state, cell_state]\n",
        "        lstm_out, final_hidden, final_cell = self.lstm_unit(lstm_input, initial_state=initial_states)\n",
        "        return lstm_out, final_hidden, final_cell\n",
        "\n",
        "    def _create_vocabulary_predictions(self, lstm_output):\n",
        "        \"\"\"Convert LSTM output to vocabulary predictions\"\"\"\n",
        "        # Reshape output for dense layer\n",
        "        reshaped_out = tf.reshape(lstm_output, (-1, lstm_output.shape[2]))\n",
        "\n",
        "        # Generate predictions\n",
        "        vocab_predictions = self.prediction_layer(reshaped_out)\n",
        "        return vocab_predictions\n",
        "\n",
        "    def call(self, x, hidden, enc_output, cell_state):\n",
        "        \"\"\"Execute complete LSTM decoder forward pass\"\"\"\n",
        "        # Stage 1: Attention computation\n",
        "        context_vector, attention_weights = self._extract_attention_context(hidden, enc_output)\n",
        "\n",
        "        # Stage 2: Input preparation\n",
        "        combined_input = self._combine_context_with_input(x, context_vector)\n",
        "\n",
        "        # Stage 3: LSTM processing\n",
        "        lstm_output, new_hidden, new_cell = self._process_lstm_forward(\n",
        "            combined_input, hidden, cell_state\n",
        "        )\n",
        "\n",
        "        # Stage 4: Final prediction generation\n",
        "        final_predictions = self._create_vocabulary_predictions(lstm_output)\n",
        "\n",
        "        return final_predictions, [new_hidden, new_cell], attention_weights\n",
        "\n",
        "\n",
        "'''\n",
        "RNN Decoder Implementation - Refactored\n",
        "'''\n",
        "class RNN_Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, dropout=0):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        # Parameter storage\n",
        "        self.batch_size = batch_sz\n",
        "        self.hidden_units = dec_units\n",
        "        self.vocabulary_count = vocab_size\n",
        "        self.word_vector_dim = embedding_dim\n",
        "\n",
        "        # Initialize all layers in __init__\n",
        "        self.vocabulary_embeddings = tf.keras.layers.Embedding(\n",
        "            input_dim=self.vocabulary_count,\n",
        "            output_dim=self.word_vector_dim\n",
        "        )\n",
        "\n",
        "        self.simple_rnn = tf.keras.layers.SimpleRNN(\n",
        "            units=self.hidden_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.vocabulary_classifier = tf.keras.layers.Dense(units=self.vocabulary_count)\n",
        "        self.attention_calculator = BahdanauAttention(self.hidden_units)\n",
        "\n",
        "    def _get_attention_information(self, current_state, encoder_outputs):\n",
        "        \"\"\"Derive attention context and importance weights\"\"\"\n",
        "        context_information, importance_weights = self.attention_calculator(\n",
        "            current_state, encoder_outputs\n",
        "        )\n",
        "        return context_information, importance_weights\n",
        "\n",
        "    def _convert_tokens_to_embeddings(self, token_sequence):\n",
        "        \"\"\"Convert token sequence to embedding vectors\"\"\"\n",
        "        embedded_sequence = self.vocabulary_embeddings(token_sequence)\n",
        "        return embedded_sequence\n",
        "\n",
        "    def _merge_attention_and_embeddings(self, token_embeddings, attention_context):\n",
        "        \"\"\"Combine attention information with input embeddings\"\"\"\n",
        "        # Reshape attention for concatenation\n",
        "        attention_expanded = tf.expand_dims(attention_context, axis=1)\n",
        "\n",
        "        # Concatenate information sources\n",
        "        fused_representation = tf.concat([attention_expanded, token_embeddings], axis=-1)\n",
        "        return fused_representation\n",
        "\n",
        "    def _run_rnn_forward_pass(self, rnn_input):\n",
        "        \"\"\"Perform RNN forward pass computation\"\"\"\n",
        "        sequence_output, final_state = self.simple_rnn(rnn_input)\n",
        "        return sequence_output, final_state\n",
        "\n",
        "    def _generate_vocabulary_scores(self, rnn_output):\n",
        "        \"\"\"Transform RNN output to vocabulary probability distribution\"\"\"\n",
        "        # Flatten output for classification\n",
        "        flattened_features = tf.reshape(rnn_output, (-1, rnn_output.shape[2]))\n",
        "\n",
        "        # Compute vocabulary scores\n",
        "        vocabulary_logits = self.vocabulary_classifier(flattened_features)\n",
        "        return vocabulary_logits\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        \"\"\"Complete RNN decoder forward computation\"\"\"\n",
        "        # Step 1: Attention mechanism computation\n",
        "        attention_context, attention_weights = self._get_attention_information(hidden, enc_output)\n",
        "\n",
        "        # Step 2: Input token processing\n",
        "        token_embeddings = self._convert_tokens_to_embeddings(x)\n",
        "\n",
        "        # Step 3: Information fusion\n",
        "        decoder_input = self._merge_attention_and_embeddings(token_embeddings, attention_context)\n",
        "\n",
        "        # Step 4: RNN processing\n",
        "        rnn_output, final_state = self._run_rnn_forward_pass(decoder_input)\n",
        "\n",
        "        # Step 5: Vocabulary prediction\n",
        "        output_predictions = self._generate_vocabulary_scores(rnn_output)\n",
        "\n",
        "        return output_predictions, final_state, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hPS--UX69DAJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Fucntion - Calculating the loss function\n",
        "Reference: https://stackoverflow.com/questions/62916592/loss-function-for-sequences-in-tensorflow-2-0\n",
        "'''\n",
        "def calculate_loss(real, pred):\n",
        "  mask_position = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_value = loss_object(real, pred)\n",
        "\n",
        "  mask_position = tf.cast(mask_position, dtype=loss_value.dtype)\n",
        "  loss_value *= mask_position\n",
        "\n",
        "  #returns the mean of the loss value\n",
        "  return tf.reduce_mean(loss_value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tRUWwazt7sfH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modular RNN Encoder-Decoder Model Builder for Sequence-to-Sequence Learning\n",
        "\n",
        "This implements a flexible and modular approach to constructing encoder-decoder architectures using different types of recurrent neural networks (GRU, LSTM, or vanilla RNN). It provides both a concise and verbose method for building and testing these models, including separate functions to initialize, test, and display model configurations. The modular design allows for easy experimentation with various RNN types by simply changing the global `rnn_type` variable.\n"
      ],
      "metadata": {
        "id": "aU-MMwF-8j_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(vocab_inp_size, vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout, train_input_batch):\n",
        "    \"\"\"\n",
        "    Construct encoder-decoder architecture based on specified RNN type\n",
        "    Refactored implementation with modular helper functions\n",
        "    \"\"\"\n",
        "    # Phase 1: Initialize and test encoder component\n",
        "    encoder_instance, encoder_states = _create_and_test_encoder(\n",
        "        vocab_inp_size, embedding_dim, units, BATCH_SIZE, dropout, train_input_batch\n",
        "    )\n",
        "\n",
        "    # Phase 2: Initialize and test decoder component\n",
        "    decoder_instance = _create_and_test_decoder(\n",
        "        vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout, encoder_states\n",
        "    )\n",
        "\n",
        "    return encoder_instance, decoder_instance\n",
        "\n",
        "\n",
        "def _create_and_test_encoder(input_vocab_size, embed_dim, hidden_units, batch_sz, dropout_rate, input_batch):\n",
        "    \"\"\"\n",
        "    Factory function to create appropriate encoder based on RNN type\n",
        "    \"\"\"\n",
        "    # Step 1: Determine encoder architecture\n",
        "    encoder_model = _instantiate_encoder_architecture(\n",
        "        input_vocab_size, embed_dim, hidden_units, batch_sz, dropout_rate\n",
        "    )\n",
        "\n",
        "    # Step 2: Initialize encoder states\n",
        "    initial_states = _initialize_encoder_states(encoder_model)\n",
        "\n",
        "    # Step 3: Perform forward pass test\n",
        "    encoder_output, final_states = _execute_encoder_forward_pass(\n",
        "        encoder_model, input_batch, initial_states\n",
        "    )\n",
        "\n",
        "    # Step 4: Display encoder information\n",
        "    _display_encoder_specifications(encoder_output, final_states)\n",
        "\n",
        "    # Step 5: Package encoder states for decoder\n",
        "    packaged_states = _package_encoder_states(final_states, encoder_output)\n",
        "\n",
        "    return encoder_model, packaged_states\n",
        "\n",
        "\n",
        "def _instantiate_encoder_architecture(vocab_size, embedding_size, num_units, batch_size, dropout_prob):\n",
        "    \"\"\"\n",
        "    Create encoder instance based on global RNN type configuration\n",
        "    \"\"\"\n",
        "    encoder_mapping = {\n",
        "        'GRU': lambda: GRU_Encoder(vocab_size, embedding_size, num_units, batch_size, dropout_prob),\n",
        "        'LSTM': lambda: LSTM_Encoder(vocab_size, embedding_size, num_units, batch_size, dropout_prob),\n",
        "        'RNN': lambda: RNN_Encoder(vocab_size, embedding_size, num_units, batch_size, dropout_prob)\n",
        "    }\n",
        "\n",
        "    if rnn_type in encoder_mapping:\n",
        "        encoder_instance = encoder_mapping[rnn_type]()\n",
        "        return encoder_instance\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported RNN type: {rnn_type}\")\n",
        "\n",
        "\n",
        "def _initialize_encoder_states(encoder_model):\n",
        "    \"\"\"\n",
        "    Initialize hidden states for the encoder based on its type\n",
        "    \"\"\"\n",
        "    if rnn_type == 'GRU':\n",
        "        hidden_state = encoder_model.initialize_hidden_state()\n",
        "        return {'hidden': hidden_state}\n",
        "    elif rnn_type == 'LSTM':\n",
        "        hidden_state, cell_state = encoder_model.initialize_hidden_state()\n",
        "        return {'hidden': hidden_state, 'cell': cell_state}\n",
        "    elif rnn_type == 'RNN':\n",
        "        hidden_state = encoder_model.initialize_hidden_state()\n",
        "        return {'hidden': hidden_state}\n",
        "\n",
        "\n",
        "def _execute_encoder_forward_pass(encoder_model, input_sequence, state_dict):\n",
        "    \"\"\"\n",
        "    Run forward pass through encoder with appropriate state handling\n",
        "    \"\"\"\n",
        "    if rnn_type == 'GRU':\n",
        "        output, final_hidden = encoder_model(input_sequence, state_dict['hidden'])\n",
        "        return output, {'hidden': final_hidden, 'output': output}\n",
        "    elif rnn_type == 'LSTM':\n",
        "        output, final_hidden, final_cell = encoder_model(\n",
        "            input_sequence, state_dict['hidden'], state_dict['cell']\n",
        "        )\n",
        "        return output, {'hidden': final_hidden, 'cell': final_cell, 'output': output}\n",
        "    elif rnn_type == 'RNN':\n",
        "        output, final_hidden = encoder_model(input_sequence, state_dict['hidden'])\n",
        "        return output, {'hidden': final_hidden, 'output': output}\n",
        "\n",
        "\n",
        "def _display_encoder_specifications(encoder_output, state_information):\n",
        "    \"\"\"\n",
        "    Print encoder output dimensions and specifications\n",
        "    \"\"\"\n",
        "    # Display encoder output shape\n",
        "    output_shape_info = f'Encoder output shape: (batch size, sequence length, units) {encoder_output.shape}'\n",
        "    print(output_shape_info)\n",
        "\n",
        "    # Display hidden state shape\n",
        "    hidden_shape_info = f'Encoder Hidden state shape: (batch size, units) {state_information[\"hidden\"].shape}'\n",
        "    print(hidden_shape_info)\n",
        "\n",
        "    # Display additional state info for LSTM\n",
        "    if rnn_type == 'LSTM' and 'cell' in state_information:\n",
        "        cell_shape_info = f'Encoder Cell state shape: (batch size, units) {state_information[\"cell\"].shape}'\n",
        "        print(cell_shape_info)\n",
        "\n",
        "\n",
        "def _package_encoder_states(final_states, encoder_output):\n",
        "    \"\"\"\n",
        "    Package encoder states and outputs for decoder initialization\n",
        "    \"\"\"\n",
        "    packaged_data = {\n",
        "        'hidden_state': final_states['hidden'],\n",
        "        'encoder_output': encoder_output,\n",
        "        'rnn_architecture': rnn_type\n",
        "    }\n",
        "\n",
        "    # Add cell state for LSTM\n",
        "    if rnn_type == 'LSTM' and 'cell' in final_states:\n",
        "        packaged_data['cell_state'] = final_states['cell']\n",
        "\n",
        "    return packaged_data\n",
        "\n",
        "\n",
        "def _create_and_test_decoder(target_vocab_size, embed_dim, hidden_units, batch_sz, dropout_rate, encoder_states):\n",
        "    \"\"\"\n",
        "    Factory function to create and test appropriate decoder\n",
        "    \"\"\"\n",
        "    # Step 1: Create decoder architecture\n",
        "    decoder_model = _instantiate_decoder_architecture(\n",
        "        target_vocab_size, embed_dim, hidden_units, batch_sz, dropout_rate\n",
        "    )\n",
        "\n",
        "    # Step 2: Prepare test input for decoder\n",
        "    test_decoder_input = _prepare_decoder_test_input(batch_sz)\n",
        "\n",
        "    # Step 3: Execute decoder forward pass\n",
        "    decoder_output = _execute_decoder_forward_pass(\n",
        "        decoder_model, test_decoder_input, encoder_states\n",
        "    )\n",
        "\n",
        "    # Step 4: Display decoder specifications\n",
        "    _display_decoder_specifications(decoder_output)\n",
        "\n",
        "    return decoder_model\n",
        "\n",
        "\n",
        "def _instantiate_decoder_architecture(vocab_size, embedding_size, num_units, batch_size, dropout_prob):\n",
        "    \"\"\"\n",
        "    Create decoder instance based on RNN type\n",
        "    \"\"\"\n",
        "    decoder_factory = {\n",
        "        'GRU': GRU_Decoder,\n",
        "        'LSTM': LSTM_Decoder,\n",
        "        'RNN': RNN_Decoder\n",
        "    }\n",
        "\n",
        "    if rnn_type in decoder_factory:\n",
        "        decoder_class = decoder_factory[rnn_type]\n",
        "        decoder_instance = decoder_class(vocab_size, embedding_size, num_units, batch_size, dropout_prob)\n",
        "        return decoder_instance\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown RNN type for decoder: {rnn_type}\")\n",
        "\n",
        "\n",
        "def _prepare_decoder_test_input(batch_size):\n",
        "    \"\"\"\n",
        "    Generate random test input for decoder validation\n",
        "    \"\"\"\n",
        "    # Create random uniform input tensor\n",
        "    random_input_shape = (batch_size, 1)\n",
        "    test_input = tf.random.uniform(random_input_shape)\n",
        "    return test_input\n",
        "\n",
        "\n",
        "def _execute_decoder_forward_pass(decoder_model, test_input, encoder_information):\n",
        "    \"\"\"\n",
        "    Run decoder forward pass with appropriate state handling\n",
        "    \"\"\"\n",
        "    hidden_state = encoder_information['hidden_state']\n",
        "    encoder_output = encoder_information['encoder_output']\n",
        "    architecture_type = encoder_information['rnn_architecture']\n",
        "\n",
        "    if architecture_type == 'GRU':\n",
        "        output, _, _ = decoder_model(test_input, hidden_state, encoder_output)\n",
        "        return output\n",
        "    elif architecture_type == 'LSTM':\n",
        "        cell_state = encoder_information['cell_state']\n",
        "        output, _, _ = decoder_model(test_input, hidden_state, encoder_output, cell_state)\n",
        "        return output\n",
        "    elif architecture_type == 'RNN':\n",
        "        output, _, _ = decoder_model(test_input, hidden_state, encoder_output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def _display_decoder_specifications(decoder_output_tensor):\n",
        "    \"\"\"\n",
        "    Print decoder output shape and specifications\n",
        "    \"\"\"\n",
        "    shape_description = f'Decoder output shape: (batch_size, vocab size) {decoder_output_tensor.shape}'\n",
        "    print(shape_description)\n",
        "\n",
        "\n",
        "# Alternative verbose implementation with manual loops\n",
        "def build_model_verbose(vocab_inp_size, vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout, train_input_batch):\n",
        "    \"\"\"\n",
        "    Alternative implementation with more verbose, step-by-step processing\n",
        "    \"\"\"\n",
        "    # Initialize variables\n",
        "    encoder_instance = None\n",
        "    decoder_instance = None\n",
        "    encoder_states = None\n",
        "\n",
        "    # Manual encoder selection (newbie-style approach)\n",
        "    available_rnn_types = ['GRU', 'LSTM', 'RNN']\n",
        "    selected_type = None\n",
        "\n",
        "    # Find matching RNN type\n",
        "    for i in range(len(available_rnn_types)):\n",
        "        current_type = available_rnn_types[i]\n",
        "        if current_type == rnn_type:\n",
        "            selected_type = current_type\n",
        "            break\n",
        "\n",
        "    # Create encoder based on selection\n",
        "    if selected_type == 'GRU':\n",
        "        encoder_instance = _build_gru_encoder_manually(vocab_inp_size, embedding_dim, units, BATCH_SIZE, dropout, train_input_batch)\n",
        "    elif selected_type == 'LSTM':\n",
        "        encoder_instance = _build_lstm_encoder_manually(vocab_inp_size, embedding_dim, units, BATCH_SIZE, dropout, train_input_batch)\n",
        "    elif selected_type == 'RNN':\n",
        "        encoder_instance = _build_rnn_encoder_manually(vocab_inp_size, embedding_dim, units, BATCH_SIZE, dropout, train_input_batch)\n",
        "\n",
        "    # Extract encoder information\n",
        "    encoder_model = encoder_instance['model']\n",
        "    encoder_states = encoder_instance['states']\n",
        "\n",
        "    # Create decoder with manual approach\n",
        "    if selected_type == 'GRU':\n",
        "        decoder_instance = _build_gru_decoder_manually(vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout, encoder_states)\n",
        "    elif selected_type == 'LSTM':\n",
        "        decoder_instance = _build_lstm_decoder_manually(vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout, encoder_states)\n",
        "    elif selected_type == 'RNN':\n",
        "        decoder_instance = _build_rnn_decoder_manually(vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout, encoder_states)\n",
        "\n",
        "    return encoder_model, decoder_instance\n",
        "\n",
        "\n",
        "def _build_gru_encoder_manually(vocab_size, embed_dim, units, batch_size, dropout, input_batch):\n",
        "    \"\"\"Manual GRU encoder construction\"\"\"\n",
        "    encoder = GRU_Encoder(vocab_size, embed_dim, units, batch_size, dropout)\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    output, final_hidden = encoder(input_batch, hidden)\n",
        "\n",
        "    print(f'Encoder output shape: (batch size, sequence length, units) {output.shape}')\n",
        "    print(f'Encoder Hidden state shape: (batch size, units) {final_hidden.shape}')\n",
        "\n",
        "    return {'model': encoder, 'states': {'hidden': final_hidden, 'output': output}}\n",
        "\n",
        "\n",
        "def _build_lstm_encoder_manually(vocab_size, embed_dim, units, batch_size, dropout, input_batch):\n",
        "    \"\"\"Manual LSTM encoder construction\"\"\"\n",
        "    encoder = LSTM_Encoder(vocab_size, embed_dim, units, batch_size, dropout)\n",
        "    hidden, cell = encoder.initialize_hidden_state()\n",
        "    output, final_hidden, final_cell = encoder(input_batch, hidden, cell)\n",
        "\n",
        "    print(f'Encoder output shape: (batch size, sequence length, units) {output.shape}')\n",
        "    print(f'Encoder Hidden state shape: (batch size, units) {final_hidden.shape}')\n",
        "\n",
        "    return {'model': encoder, 'states': {'hidden': final_hidden, 'cell': final_cell, 'output': output}}\n",
        "\n",
        "\n",
        "def _build_rnn_encoder_manually(vocab_size, embed_dim, units, batch_size, dropout, input_batch):\n",
        "    \"\"\"Manual RNN encoder construction\"\"\"\n",
        "    encoder = RNN_Encoder(vocab_size, embed_dim, units, batch_size, dropout)\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    output, final_hidden = encoder(input_batch, hidden)\n",
        "\n",
        "    print(f'Encoder output shape: (batch size, sequence length, units) {output.shape}')\n",
        "    print(f'Encoder Hidden state shape: (batch size, units) {final_hidden.shape}')\n",
        "\n",
        "    return {'model': encoder, 'states': {'hidden': final_hidden, 'output': output}}\n",
        "\n",
        "\n",
        "def _build_gru_decoder_manually(vocab_size, embed_dim, units, batch_size, dropout, encoder_states):\n",
        "    \"\"\"Manual GRU decoder construction\"\"\"\n",
        "    decoder = GRU_Decoder(vocab_size, embed_dim, units, batch_size, dropout)\n",
        "    test_input = tf.random.uniform((batch_size, 1))\n",
        "    output, _, _ = decoder(test_input, encoder_states['hidden'], encoder_states['output'])\n",
        "\n",
        "    print(f'Decoder output shape: (batch_size, vocab size) {output.shape}')\n",
        "    return decoder\n",
        "\n",
        "\n",
        "def _build_lstm_decoder_manually(vocab_size, embed_dim, units, batch_size, dropout, encoder_states):\n",
        "    \"\"\"Manual LSTM decoder construction\"\"\"\n",
        "    decoder = LSTM_Decoder(vocab_size, embed_dim, units, batch_size, dropout)\n",
        "    test_input = tf.random.uniform((batch_size, 1))\n",
        "    output, _, _ = decoder(test_input, encoder_states['hidden'], encoder_states['output'], encoder_states['cell'])\n",
        "\n",
        "    print(f'Decoder output shape: (batch_size, vocab size) {output.shape}')\n",
        "    return decoder\n",
        "\n",
        "\n",
        "def _build_rnn_decoder_manually(vocab_size, embed_dim, units, batch_size, dropout, encoder_states):\n",
        "    \"\"\"Manual RNN decoder construction\"\"\"\n",
        "    decoder = RNN_Decoder(vocab_size, embed_dim, units, batch_size, dropout)\n",
        "    test_input = tf.random.uniform((batch_size, 1))\n",
        "    output, _, _ = decoder(test_input, encoder_states['hidden'], encoder_states['output'])\n",
        "\n",
        "    print(f'Decoder output shape: (batch_size, vocab size) {output.shape}')\n",
        "    return decoder\n"
      ],
      "metadata": {
        "id": "xGUVdtvkNyTS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop for RNN-Based Seq2Seq Model with Modular Epoch and Batch Management\n",
        "\n",
        "This function defines a structured multi-epoch training loop for sequence-to-sequence models using GRU, LSTM, or RNN architectures. It modularizes key training operations such as state initialization, batch training, checkpointing, and logging. This design promotes clarity, flexibility, and ease of maintenance while tracking loss progression across epochs.\n"
      ],
      "metadata": {
        "id": "3FL3wEZm84Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epochs(EPOCHS, encoder, decoder, dataset, steps_per_epoch):\n",
        "    \"\"\"Main training loop for multiple epochs with refactored internal structure\"\"\"\n",
        "\n",
        "    def get_initial_encoder_states():\n",
        "        \"\"\"Get initial encoder states based on RNN type\"\"\"\n",
        "        if rnn_type == 'LSTM':\n",
        "            hidden_state, cell_state = encoder.initialize_hidden_state()\n",
        "            return [hidden_state, cell_state]\n",
        "        else:  # GRU or RNN\n",
        "            return encoder.initialize_hidden_state()\n",
        "\n",
        "    def execute_batch_training(batch_data, encoder_states):\n",
        "        \"\"\"Execute training for a single batch\"\"\"\n",
        "        input_data, target_data = batch_data\n",
        "        return train_batch(input_data, target_data, encoder_states, encoder, decoder, rnn_type)\n",
        "\n",
        "    def handle_batch_logging(epoch_num, batch_num, loss_value):\n",
        "        \"\"\"Handle periodic batch logging\"\"\"\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f'Epoch {epoch_num+1} Batch {batch_num} Loss {loss_value.numpy():.4f}')\n",
        "\n",
        "    def manage_checkpoint_saving(epoch_num):\n",
        "        \"\"\"Manage checkpoint saving at regular intervals\"\"\"\n",
        "        if (epoch_num + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    def finalize_epoch_results(epoch_num, total_loss_value, start_time):\n",
        "        \"\"\"Calculate and display epoch results\"\"\"\n",
        "        average_loss = total_loss_value / steps_per_epoch\n",
        "        time_elapsed = time.time() - start_time\n",
        "\n",
        "        print(f'Epoch {epoch_num+1} Loss {average_loss:.4f}')\n",
        "        print(f'Time taken for 1 epoch {time_elapsed:.2f} sec\\n')\n",
        "\n",
        "        return average_loss\n",
        "\n",
        "    # Main training loop implementation\n",
        "    loss_tracking = [0] * EPOCHS\n",
        "\n",
        "    for epoch_index in range(EPOCHS):\n",
        "        timer_start = time.time()\n",
        "\n",
        "        # Set up encoder states for this epoch\n",
        "        encoder_initial_states = get_initial_encoder_states()\n",
        "\n",
        "        # Track cumulative loss for the epoch\n",
        "        cumulative_loss = 0\n",
        "        batch_index = 0\n",
        "\n",
        "        # Iterate through dataset batches\n",
        "        for batch_index, current_batch in enumerate(dataset.take(steps_per_epoch)):\n",
        "            # Process current batch and get loss\n",
        "            batch_loss_result = execute_batch_training(current_batch, encoder_initial_states)\n",
        "\n",
        "            # Accumulate loss\n",
        "            cumulative_loss += batch_loss_result\n",
        "\n",
        "            # Log progress if needed\n",
        "            handle_batch_logging(epoch_index, batch_index, batch_loss_result)\n",
        "\n",
        "        # Handle epoch completion tasks\n",
        "        manage_checkpoint_saving(epoch_index)\n",
        "\n",
        "        # Calculate and log epoch summary\n",
        "        epoch_avg_loss = finalize_epoch_results(epoch_index, cumulative_loss, timer_start)\n",
        "\n",
        "        # Store the average loss for this epoch\n",
        "        loss_tracking[epoch_index] = epoch_avg_loss.numpy()\n",
        "\n",
        "    return loss_tracking"
      ],
      "metadata": {
        "id": "t0hlWYxWaq9Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modular Seq2Seq Training Pipeline with Optional WandB Support\n",
        "\n",
        "This pipeline orchestrates the full training process for RNN-based sequence-to-sequence models using TensorFlow.\n",
        "\n",
        "### Core Functions:\n",
        "\n",
        "- **Experiment Setup**: `_configure_wandb_experiment` initializes WandB or defaults hyperparameters.\n",
        "- **Data Handling**: `_compute_dataset_metrics` and `_build_training_pipeline` prepare and batch the dataset.\n",
        "- **Model Creation**: `_create_model_architecture` builds the encoder-decoder and sets up training components.\n",
        "- **Checkpointing**: `_establish_checkpointing` manages model saving/restoration.\n",
        "- **Training Loop**: `_run_training_epochs` runs training with logging and periodic checkpointing.\n",
        "- **Evaluation**: `_evaluate_model_performance` validates and logs accuracy.\n",
        "- **Execution**: `train` coordinates the full workflow.\n",
        "\n",
        "Supports clean modularity, WandB logging, and easy hyperparameter tuning.\n"
      ],
      "metadata": {
        "id": "zii3k17E9KZV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FEuZduf39E2J"
      },
      "outputs": [],
      "source": [
        "def _configure_wandb_experiment(use_wandb=True):\n",
        "    \"\"\"Setup wandb configuration and extract hyperparameters\"\"\"\n",
        "    if not use_wandb:\n",
        "        # Return default values if wandb is not used\n",
        "        return None, {\n",
        "            'rnn_architecture': 'GRU',\n",
        "            'batch_dimension': 64,\n",
        "            'embedding_size': 256,\n",
        "            'hidden_units': 1024,\n",
        "            'training_epochs': 10,\n",
        "            'dropout_rate': 0.1\n",
        "        }\n",
        "\n",
        "    experiment_run = wandb.init()\n",
        "    hyperparameter_config = {\n",
        "        'rnn_architecture': experiment_run.config.rnn_type,\n",
        "        'batch_dimension': experiment_run.config.bs,\n",
        "        'embedding_size': experiment_run.config.embed,\n",
        "        'hidden_units': experiment_run.config.latent,\n",
        "        'training_epochs': experiment_run.config.epochs,\n",
        "        'dropout_rate': experiment_run.config.dropout\n",
        "    }\n",
        "\n",
        "    print(\"Selected RNN Architecture:\", hyperparameter_config['rnn_architecture'])\n",
        "    return experiment_run, hyperparameter_config\n",
        "\n",
        "def _compute_dataset_metrics():\n",
        "    \"\"\"Calculate dataset dimensions and vocabulary parameters\"\"\"\n",
        "    dataset_buffer_size = len(input_tensor_train)\n",
        "    epoch_steps = len(input_tensor_train) // BATCH_SIZE\n",
        "    input_vocab_dimension = len(inp_lang.word_index) + 1\n",
        "    target_vocab_dimension = len(targ_lang.word_index) + 1\n",
        "\n",
        "    return {\n",
        "        'buffer_size': dataset_buffer_size,\n",
        "        'steps_per_epoch': epoch_steps,\n",
        "        'vocab_inp_size': input_vocab_dimension,\n",
        "        'vocab_tar_size': target_vocab_dimension\n",
        "    }\n",
        "\n",
        "def _create_experiment_name(config_dict, use_wandb):\n",
        "    \"\"\"Generate unique experiment identifier from hyperparameters\"\"\"\n",
        "    name_components = [\n",
        "        f\"_epochs_{config_dict['training_epochs']}\",\n",
        "        f\"_rnn_type_{config_dict['rnn_architecture']}\",\n",
        "        f\"_bs_{config_dict['batch_dimension']}\",\n",
        "        f\"_embed_{config_dict['embedding_size']}\",\n",
        "        f\"_latent_{config_dict['hidden_units']}\",\n",
        "        f\"_dropout_{config_dict['dropout_rate']}\"\n",
        "    ]\n",
        "\n",
        "    experiment_name = ''.join(name_components)\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.run.name = experiment_name\n",
        "\n",
        "    return experiment_name\n",
        "\n",
        "def _build_training_pipeline():\n",
        "    \"\"\"Create and configure the training data pipeline\"\"\"\n",
        "    dataset_metrics = _compute_dataset_metrics()\n",
        "\n",
        "    # Build tensor dataset with shuffling\n",
        "    data_pipeline = tf.data.Dataset.from_tensor_slices(\n",
        "        (input_tensor_train, target_tensor_train)\n",
        "    ).shuffle(dataset_metrics['buffer_size'])\n",
        "\n",
        "    # Apply batching with remainder dropping\n",
        "    batched_pipeline = data_pipeline.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    # Get sample for model initialization\n",
        "    sample_input_batch, sample_target_batch = next(iter(batched_pipeline))\n",
        "\n",
        "    return batched_pipeline, sample_input_batch, sample_target_batch, dataset_metrics\n",
        "\n",
        "def _create_model_architecture(vocab_metrics, hyperparams, sample_data):\n",
        "    \"\"\"Build encoder-decoder model and training components\"\"\"\n",
        "    # Create model components\n",
        "    encoder_net, decoder_net = build_model(\n",
        "        vocab_metrics['vocab_inp_size'],\n",
        "        vocab_metrics['vocab_tar_size'],\n",
        "        hyperparams['embedding_size'],\n",
        "        hyperparams['hidden_units'],\n",
        "        hyperparams['batch_dimension'],\n",
        "        hyperparams['dropout_rate'],\n",
        "        sample_data\n",
        "    )\n",
        "\n",
        "    # Initialize training components\n",
        "    training_optimizer = tf.keras.optimizers.Adam()\n",
        "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none'\n",
        "    )\n",
        "\n",
        "    return encoder_net, decoder_net, training_optimizer, loss_function\n",
        "\n",
        "def _establish_checkpointing(encoder_net, decoder_net, training_optimizer):\n",
        "    \"\"\"Setup model checkpointing infrastructure\"\"\"\n",
        "    checkpoint_storage_dir = os.path.join(os.getcwd(), 'training_checkpoints')\n",
        "    checkpoint_path_prefix = os.path.join(checkpoint_storage_dir, \"ckpt\")\n",
        "\n",
        "    checkpoint_handler = tf.train.Checkpoint(\n",
        "        optimizer=training_optimizer,\n",
        "        encoder=encoder_net,\n",
        "        decoder=decoder_net\n",
        "    )\n",
        "\n",
        "    return checkpoint_handler, checkpoint_path_prefix\n",
        "\n",
        "def _run_training_epochs(hyperparams, data_pipeline, dataset_metrics,\n",
        "                        encoder_net, decoder_net, use_wandb):\n",
        "    \"\"\"Execute the complete training process across all epochs\"\"\"\n",
        "    epoch_losses = [0] * hyperparams['training_epochs']\n",
        "    architecture_type = hyperparams['rnn_architecture']\n",
        "\n",
        "    for current_epoch in range(hyperparams['training_epochs']):\n",
        "        epoch_timer = time.time()\n",
        "\n",
        "        # Setup encoder initial states\n",
        "        if architecture_type != 'LSTM':\n",
        "            initial_hidden = encoder_net.initialize_hidden_state()\n",
        "            encoder_states = initial_hidden\n",
        "        else:\n",
        "            hidden_state, cell_state = encoder_net.initialize_hidden_state()\n",
        "            encoder_states = [hidden_state, cell_state]\n",
        "\n",
        "        # Process epoch batches\n",
        "        accumulated_loss = 0\n",
        "        final_batch_idx = 0\n",
        "\n",
        "        for final_batch_idx, (batch_input, batch_target) in enumerate(\n",
        "            data_pipeline.take(dataset_metrics['steps_per_epoch'])\n",
        "        ):\n",
        "            # Train single batch\n",
        "            batch_loss_value = train_batch(\n",
        "                batch_input, batch_target, encoder_states,\n",
        "                encoder_net, decoder_net, architecture_type\n",
        "            )\n",
        "            accumulated_loss += batch_loss_value\n",
        "\n",
        "        # Periodic batch logging\n",
        "        if final_batch_idx % 100 == 0:\n",
        "            print(f'Epoch {current_epoch+1} Batch {final_batch_idx} '\n",
        "                  f'Loss {batch_loss_value.numpy():.4f}')\n",
        "\n",
        "        # Checkpoint saving\n",
        "        if (current_epoch + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "        # Epoch summary\n",
        "        mean_epoch_loss = accumulated_loss / dataset_metrics['steps_per_epoch']\n",
        "        elapsed_time = time.time() - epoch_timer\n",
        "\n",
        "        print(f'Epoch {current_epoch+1} Loss {mean_epoch_loss:.4f}')\n",
        "        print(f'Time taken for 1 epoch {elapsed_time:.2f} sec\\n')\n",
        "\n",
        "        # Store and log results\n",
        "        epoch_losses[current_epoch] = mean_epoch_loss.numpy()\n",
        "        if use_wandb:\n",
        "            wandb.log({\"train_loss\": mean_epoch_loss.numpy()})\n",
        "\n",
        "    return epoch_losses\n",
        "\n",
        "def _evaluate_model_performance(experiment_id, architecture_type, use_wandb):\n",
        "    \"\"\"Perform model validation and metric logging\"\"\"\n",
        "    model_accuracy = validate(vaildation_file_path, architecture_type)\n",
        "\n",
        "    print(\"Model Validation Accuracy:\", model_accuracy)\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log({'val_accuracy': model_accuracy})\n",
        "\n",
        "    return model_accuracy\n",
        "\n",
        "def _load_final_checkpoint():\n",
        "    \"\"\"Restore the most recent model checkpoint\"\"\"\n",
        "    most_recent_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    if most_recent_checkpoint:\n",
        "        checkpoint.restore(most_recent_checkpoint)\n",
        "\n",
        "def train(use_wandb=True):\n",
        "    \"\"\"Refactored main training orchestration function\"\"\"\n",
        "    # Global variable declarations\n",
        "    global BATCH_SIZE, units, vocab_inp_size, vocab_tar_size\n",
        "    global embedding_dim, encoder, decoder, optimizer, loss_object\n",
        "    global checkpoint_dir, checkpoint_prefix, checkpoint, run_name, rnn_type\n",
        "\n",
        "    # Phase 1: Experiment configuration\n",
        "    wandb_session, config_parameters = _configure_wandb_experiment(use_wandb)\n",
        "\n",
        "    # Phase 2: Global parameter assignment\n",
        "    rnn_type = config_parameters['rnn_architecture']\n",
        "    BATCH_SIZE = config_parameters['batch_dimension']\n",
        "    embedding_dim = config_parameters['embedding_size']\n",
        "    units = config_parameters['hidden_units']\n",
        "    EPOCHS = config_parameters['training_epochs']\n",
        "    dropout = config_parameters['dropout_rate']\n",
        "\n",
        "    # Phase 3: Dataset preparation\n",
        "    training_data, sample_inp, sample_targ, data_metrics = _build_training_pipeline()\n",
        "\n",
        "    # Phase 4: Global vocabulary assignment\n",
        "    vocab_inp_size = data_metrics['vocab_inp_size']\n",
        "    vocab_tar_size = data_metrics['vocab_tar_size']\n",
        "\n",
        "    # Phase 5: Experiment naming\n",
        "    run_name = _create_experiment_name(config_parameters, use_wandb)\n",
        "\n",
        "    # Phase 6: Model and optimizer creation\n",
        "    encoder, decoder, optimizer, loss_object = _create_model_architecture(\n",
        "        data_metrics, config_parameters, sample_inp\n",
        "    )\n",
        "\n",
        "    # Phase 7: Checkpoint system setup\n",
        "    checkpoint, checkpoint_prefix = _establish_checkpointing(encoder, decoder, optimizer)\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_prefix)\n",
        "\n",
        "    # Phase 8: Main training execution\n",
        "    loss_progression = _run_training_epochs(\n",
        "        config_parameters, training_data, data_metrics, encoder, decoder, use_wandb\n",
        "    )\n",
        "\n",
        "    # Phase 9: Model evaluation\n",
        "    final_accuracy = _evaluate_model_performance(run_name, rnn_type, use_wandb)\n",
        "\n",
        "    # Phase 10: Results summary\n",
        "    print(\"Complete Training Loss History:\", loss_progression)\n",
        "    print(\"Final Model Validation Score:\", final_accuracy)\n",
        "\n",
        "    # Phase 11: Checkpoint restoration\n",
        "    _load_final_checkpoint()\n",
        "\n",
        "    return loss_progression, final_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MQW3p5ETAFCu"
      },
      "outputs": [],
      "source": [
        "def configure_model_parameters():\n",
        "    \"\"\"\n",
        "    Initialize and return the optimal hyperparameters for model training\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        'rnn_architecture': 'LSTM',\n",
        "        'batch_size': 64,\n",
        "        'embedding_dimensions': 512,\n",
        "        'hidden_units': 1024,\n",
        "        'training_epochs': 20,\n",
        "        'dropout_rate': 0.2\n",
        "    }\n",
        "\n",
        "    print(f\"RNN Architecture: {config['rnn_architecture']}\")\n",
        "    return config\n",
        "\n",
        "def calculate_training_metrics(config):\n",
        "    \"\"\"\n",
        "    Calculate buffer size, steps per epoch, and vocabulary sizes\n",
        "    \"\"\"\n",
        "    buffer_size = len(input_tensor_train)\n",
        "    steps_per_epoch = len(input_tensor_train) // config['batch_size']\n",
        "    input_vocab_size = len(inp_lang.word_index) + 1\n",
        "    target_vocab_size = len(targ_lang.word_index) + 1\n",
        "\n",
        "    return buffer_size, steps_per_epoch, input_vocab_size, target_vocab_size\n",
        "\n",
        "def generate_run_identifier(config):\n",
        "    \"\"\"\n",
        "    Create a unique identifier for the current training run\n",
        "    \"\"\"\n",
        "    identifier = (f\"_epochs_{config['training_epochs']}\"\n",
        "                 f\"_rnn_type_{config['rnn_architecture']}\"\n",
        "                 f\"_bs_{config['batch_size']}\"\n",
        "                 f\"_embed_{config['embedding_dimensions']}\"\n",
        "                 f\"_latent_{config['hidden_units']}\"\n",
        "                 f\"_dropout_{config['dropout_rate']}\")\n",
        "    return identifier\n",
        "\n",
        "def prepare_training_dataset(config, buffer_size):\n",
        "    \"\"\"\n",
        "    Create and configure the training dataset with batching\n",
        "    \"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (input_tensor_train, target_tensor_train)\n",
        "    ).shuffle(buffer_size)\n",
        "\n",
        "    # Create batches and drop incomplete final batch for consistent training\n",
        "    dataset = dataset.batch(config['batch_size'], drop_remainder=True)\n",
        "\n",
        "    # Extract sample batch for model initialization\n",
        "    sample_input, sample_target = next(iter(dataset))\n",
        "\n",
        "    return dataset, sample_input, sample_target\n",
        "\n",
        "def initialize_model_components(config, input_vocab_size, target_vocab_size, sample_input):\n",
        "    \"\"\"\n",
        "    Build encoder-decoder architecture and initialize training components\n",
        "    \"\"\"\n",
        "    # Construct the neural network architecture\n",
        "    encoder_model, decoder_model = build_model(\n",
        "        input_vocab_size,\n",
        "        target_vocab_size,\n",
        "        config['embedding_dimensions'],\n",
        "        config['hidden_units'],\n",
        "        config['batch_size'],\n",
        "        config['dropout_rate'],\n",
        "        sample_input\n",
        "    )\n",
        "\n",
        "    # Initialize loss computation\n",
        "    sparse_categorical_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none'\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model, sparse_categorical_loss\n",
        "\n",
        "def setup_optimizer_and_checkpoint(encoder_model, decoder_model):\n",
        "    \"\"\"\n",
        "    Initialize optimizer and configure checkpoint system\n",
        "    \"\"\"\n",
        "    # Create optimizer outside of any tf.function context\n",
        "    adam_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    # Build optimizer state by running a dummy forward pass\n",
        "    # This ensures the optimizer variables are created properly\n",
        "    dummy_gradients = []\n",
        "    trainable_vars = encoder_model.trainable_variables + decoder_model.trainable_variables\n",
        "\n",
        "    for var in trainable_vars:\n",
        "        dummy_gradients.append(tf.zeros_like(var))\n",
        "\n",
        "    # Initialize optimizer state\n",
        "    adam_optimizer.apply_gradients(zip(dummy_gradients, trainable_vars))\n",
        "\n",
        "    # Setup checkpoint system\n",
        "    checkpoint_directory = os.path.join(os.getcwd(), 'training_checkpoints')\n",
        "    checkpoint_file_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
        "\n",
        "    checkpoint_manager = tf.train.Checkpoint(\n",
        "        optimizer=adam_optimizer,\n",
        "        encoder=encoder_model,\n",
        "        decoder=decoder_model\n",
        "    )\n",
        "\n",
        "    return adam_optimizer, checkpoint_directory, checkpoint_file_prefix, checkpoint_manager\n",
        "\n",
        "def execute_training_process(config, encoder_model, decoder_model, dataset, steps_per_epoch):\n",
        "    \"\"\"\n",
        "    Run the complete training loop for specified epochs\n",
        "    \"\"\"\n",
        "    training_losses = [0] * config['training_epochs']\n",
        "\n",
        "    # Execute the training procedure\n",
        "    training_losses = train_epochs(\n",
        "        config['training_epochs'],\n",
        "        encoder_model,\n",
        "        decoder_model,\n",
        "        dataset,\n",
        "        steps_per_epoch\n",
        "    )\n",
        "\n",
        "    return training_losses\n",
        "\n",
        "def evaluate_model_performance(run_identifier, rnn_architecture):\n",
        "    \"\"\"\n",
        "    Assess model performance on validation and test datasets\n",
        "    \"\"\"\n",
        "    test_performance = validate(test_file_path, run_identifier)\n",
        "    validation_performance = validate(vaildation_file_path, rnn_architecture)\n",
        "\n",
        "    return test_performance, validation_performance\n",
        "\n",
        "def restore_and_generate_outputs(checkpoint_manager, checkpoint_directory, rnn_architecture, run_identifier):\n",
        "    \"\"\"\n",
        "    Restore best model and generate sample outputs and connectivity analysis\n",
        "    \"\"\"\n",
        "    # Load the most recent checkpoint\n",
        "    checkpoint_manager.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
        "\n",
        "    # Generate sample inputs using the trained model\n",
        "    generate_inputs(rnn_architecture, 10)\n",
        "\n",
        "    # Analyze model connectivity with predefined test cases\n",
        "    test_words = ['maryaadaa', 'prayogshala', 'angarakshak']\n",
        "    output_directory = os.path.join(os.getcwd(), \"predictions_attention\", str(run_identifier))\n",
        "    connectivity(test_words, rnn_architecture, output_directory)\n",
        "\n",
        "def manual_train():\n",
        "    \"\"\"\n",
        "    Orchestrate the complete manual training process with optimal configuration\n",
        "    \"\"\"\n",
        "    # Set global variables for compatibility\n",
        "    global BATCH_SIZE, units, vocab_inp_size, vocab_tar_size, embedding_dim\n",
        "    global encoder, decoder, optimizer, loss_object\n",
        "    global checkpoint_dir, checkpoint_prefix, checkpoint, run_name, rnn_type\n",
        "\n",
        "    # Step 1: Configure hyperparameters\n",
        "    config = configure_model_parameters()\n",
        "\n",
        "    # Step 2: Calculate training metrics\n",
        "    buffer_size, steps_per_epoch, input_vocab_size, target_vocab_size = calculate_training_metrics(config)\n",
        "\n",
        "    # Step 3: Generate run identifier\n",
        "    run_identifier = generate_run_identifier(config)\n",
        "\n",
        "    # Step 4: Prepare dataset\n",
        "    dataset, sample_input, sample_target = prepare_training_dataset(config, buffer_size)\n",
        "\n",
        "    # Step 5: Initialize model components\n",
        "    encoder_model, decoder_model, sparse_categorical_loss = initialize_model_components(\n",
        "        config, input_vocab_size, target_vocab_size, sample_input\n",
        "    )\n",
        "\n",
        "    # Step 6: Setup optimizer and checkpoint system\n",
        "    adam_optimizer, checkpoint_directory, checkpoint_file_prefix, checkpoint_manager = setup_optimizer_and_checkpoint(\n",
        "        encoder_model, decoder_model\n",
        "    )\n",
        "\n",
        "    # Step 7: Execute training\n",
        "    training_losses = execute_training_process(config, encoder_model, decoder_model, dataset, steps_per_epoch)\n",
        "\n",
        "    # Step 8: Evaluate performance\n",
        "    test_performance, validation_performance = evaluate_model_performance(run_identifier, config['rnn_architecture'])\n",
        "\n",
        "    # Step 9: Display results\n",
        "    print(f\"Training losses: {training_losses}\")\n",
        "    print(f\"Validation Accuracy: {validation_performance}\")\n",
        "    print(f\"Test Accuracy: {test_performance}\")\n",
        "\n",
        "    # Step 10: Generate outputs and analysis\n",
        "    restore_and_generate_outputs(checkpoint_manager, checkpoint_directory, config['rnn_architecture'], run_identifier)\n",
        "\n",
        "    # Update global variables for backward compatibility\n",
        "    BATCH_SIZE = config['batch_size']\n",
        "    units = config['hidden_units']\n",
        "    vocab_inp_size = input_vocab_size\n",
        "    vocab_tar_size = target_vocab_size\n",
        "    embedding_dim = config['embedding_dimensions']\n",
        "    encoder = encoder_model\n",
        "    decoder = decoder_model\n",
        "    optimizer = adam_optimizer\n",
        "    loss_object = sparse_categorical_loss\n",
        "    checkpoint_dir = checkpoint_directory\n",
        "    checkpoint_prefix = checkpoint_file_prefix\n",
        "    checkpoint = checkpoint_manager\n",
        "    run_name = run_identifier\n",
        "    rnn_type = config['rnn_architecture']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Batch Execution (Seq2Seq)\n",
        "\n",
        "These functions define the core logic for processing one training batch using teacher forcing.\n",
        "\n",
        "### Core Functions:\n",
        "\n",
        "- **`initialize_encoder_states`**:\n",
        "  - Feeds input to the encoder and returns hidden (and cell) states based on RNN type (LSTM, GRU, or RNN).\n",
        "\n",
        "- **`prepare_decoder_initial_input`**:\n",
        "  - Initializes decoder input with start-of-sequence tokens.\n",
        "\n",
        "- **`execute_decoder_step`**:\n",
        "  - Runs a single step of the decoder; handles LSTM-specific state passing logic.\n",
        "\n",
        "- **`compute_sequence_loss`**:\n",
        "  - Iterates over target sequence and computes cumulative loss using teacher forcing.\n",
        "\n",
        "- **`perform_gradient_update`**:\n",
        "  - Computes gradients and updates model parameters (not used directly in current flow).\n",
        "\n",
        "### Training Loop:\n",
        "\n",
        "- **`train_batch`** (`@tf.function`-decorated):\n",
        "  - Encodes input, prepares initial decoder input, computes sequence loss,\n",
        "    calculates gradients, and updates parameters using optimizer.\n",
        "  - Returns average loss per token for the batch.\n"
      ],
      "metadata": {
        "id": "p4dSDG8E9phR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kqfHJ7e59Kpr"
      },
      "outputs": [],
      "source": [
        "def initialize_encoder_states(input_data, hidden_state, encoder_model, architecture_type):\n",
        "    \"\"\"\n",
        "    Process input through encoder and return appropriate states based on RNN architecture\n",
        "    \"\"\"\n",
        "    if architecture_type == 'LSTM':\n",
        "        # LSTM returns output, hidden state, and cell state\n",
        "        encoder_output, hidden_state, cell_state = encoder_model(\n",
        "            input_data, hidden_state[0], hidden_state[1]\n",
        "        )\n",
        "        return encoder_output, hidden_state, cell_state\n",
        "    else:\n",
        "        # GRU and vanilla RNN return output and hidden state only\n",
        "        encoder_output, hidden_state = encoder_model(input_data, hidden_state)\n",
        "        return encoder_output, hidden_state, None\n",
        "\n",
        "def prepare_decoder_initial_input(batch_size, target_tokenizer):\n",
        "    \"\"\"\n",
        "    Create the initial decoder input using start-of-sequence tokens\n",
        "    \"\"\"\n",
        "    start_token_id = target_tokenizer.word_index['\\t']\n",
        "    initial_decoder_input = tf.expand_dims([start_token_id] * batch_size, 1)\n",
        "    return initial_decoder_input\n",
        "\n",
        "def execute_decoder_step(decoder_input, decoder_hidden_state, encoder_output,\n",
        "                        decoder_model, architecture_type, step_number, cell_state=None):\n",
        "    \"\"\"\n",
        "    Execute a single decoder step with appropriate state handling for different RNN types\n",
        "    \"\"\"\n",
        "    if architecture_type == 'LSTM':\n",
        "        if step_number == 1:\n",
        "            # First LSTM step uses both hidden and cell states\n",
        "            predictions, new_hidden_state, attention_weights = decoder_model(\n",
        "                decoder_input, decoder_hidden_state, encoder_output, cell_state\n",
        "            )\n",
        "        else:\n",
        "            # Subsequent LSTM steps extract hidden state from tuple\n",
        "            predictions, new_hidden_state, attention_weights = decoder_model(\n",
        "                decoder_input, decoder_hidden_state[0], encoder_output, cell_state\n",
        "            )\n",
        "    else:\n",
        "        # GRU and vanilla RNN processing\n",
        "        predictions, new_hidden_state, attention_weights = decoder_model(\n",
        "            decoder_input, decoder_hidden_state, encoder_output\n",
        "        )\n",
        "\n",
        "    return predictions, new_hidden_state, attention_weights\n",
        "\n",
        "def compute_sequence_loss(target_sequence, decoder_model, decoder_input,\n",
        "                         decoder_hidden, encoder_output, architecture_type, cell_state=None):\n",
        "    \"\"\"\n",
        "    Calculate cumulative loss across the entire target sequence using teacher forcing\n",
        "    \"\"\"\n",
        "    cumulative_loss = 0\n",
        "    sequence_length = target_sequence.shape[1]\n",
        "\n",
        "    # Iterate through each time step in the sequence\n",
        "    for time_step in range(1, sequence_length):\n",
        "        # Get predictions for current time step\n",
        "        predictions, decoder_hidden, _ = execute_decoder_step(\n",
        "            decoder_input, decoder_hidden, encoder_output,\n",
        "            decoder_model, architecture_type, time_step, cell_state\n",
        "        )\n",
        "\n",
        "        # Accumulate loss for current prediction\n",
        "        step_loss = calculate_loss(target_sequence[:, time_step], predictions)\n",
        "        cumulative_loss += step_loss\n",
        "\n",
        "        # Apply teacher forcing: use ground truth as next input\n",
        "        decoder_input = tf.expand_dims(target_sequence[:, time_step], 1)\n",
        "\n",
        "    return cumulative_loss\n",
        "\n",
        "def perform_gradient_update(total_loss, encoder_model, decoder_model, optimizer_instance):\n",
        "    \"\"\"\n",
        "    Calculate gradients and apply parameter updates\n",
        "    \"\"\"\n",
        "    # Collect all trainable parameters from both models\n",
        "    trainable_parameters = encoder_model.trainable_variables + decoder_model.trainable_variables\n",
        "\n",
        "    # Compute gradients with respect to total loss\n",
        "    parameter_gradients = tf.gradients(total_loss, trainable_parameters)\n",
        "\n",
        "    # Apply gradient-based parameter updates\n",
        "    optimizer_instance.apply_gradients(zip(parameter_gradients, trainable_parameters))\n",
        "\n",
        "@tf.function\n",
        "def train_batch(inp, targ, enc_hidden, encoder, decoder, rnn_type):\n",
        "    \"\"\"\n",
        "    Execute training for a single batch and return normalized batch loss\n",
        "    \"\"\"\n",
        "    # Initialize total loss accumulator\n",
        "    total_sequence_loss = 0\n",
        "\n",
        "    # Use gradient tape to track operations for backpropagation\n",
        "    with tf.GradientTape() as gradient_tracker:\n",
        "        # Process input through encoder based on architecture type\n",
        "        encoder_output, decoder_hidden, cell_state = initialize_encoder_states(\n",
        "            inp, enc_hidden, encoder, rnn_type\n",
        "        )\n",
        "\n",
        "        # Prepare initial decoder input with start tokens\n",
        "        decoder_input = prepare_decoder_initial_input(BATCH_SIZE, targ_lang)\n",
        "\n",
        "        # Compute loss across entire sequence\n",
        "        total_sequence_loss = compute_sequence_loss(\n",
        "            targ, decoder, decoder_input, decoder_hidden,\n",
        "            encoder_output, rnn_type, cell_state\n",
        "        )\n",
        "\n",
        "    # Calculate normalized batch loss\n",
        "    normalized_batch_loss = total_sequence_loss / int(targ.shape[1])\n",
        "\n",
        "    # Collect trainable variables from both models\n",
        "    model_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    # Compute gradients of loss with respect to model parameters\n",
        "    loss_gradients = gradient_tracker.gradient(total_sequence_loss, model_variables)\n",
        "\n",
        "    # Apply computed gradients to update model parameters\n",
        "    optimizer.apply_gradients(zip(loss_gradients, model_variables))\n",
        "\n",
        "    return normalized_batch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Model Function\n",
        "This function generates the predicted output word from a given input word using a trained sequence-to-sequence model with attention. It handles input preprocessing, runs the encoder, and then uses the decoder iteratively to produce characters while collecting attention weights, stopping when the end-of-sequence token is predicted."
      ],
      "metadata": {
        "id": "GsoqZm6w-FKW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3KqJkihJ9PT4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Function - inference_model\n",
        "generating the predicted word, input word, attention weights and the attention plot\n",
        "'''\n",
        "def inference_model(input_word,rnn_type):\n",
        "  #creating an empty attention plot\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  #preprocessing the input word\n",
        "  input_word = word_process(input_word)\n",
        "\n",
        "  #converting the word to tensor after pading\n",
        "  inputs = [inp_lang.word_index[i] for i in input_word]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  #predicted word initialization\n",
        "  predicted_word = ''\n",
        "\n",
        "  #if cell type is GRU or RNN\n",
        "  if rnn_type!='LSTM':\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "  #if cell type is LSTM\n",
        "  elif rnn_type=='LSTM':\n",
        "    hidden=tf.zeros((1, units))\n",
        "    cell_state= tf.zeros((1, units))\n",
        "    enc_out, enc_hidden,enc_cell_state = encoder(inputs, hidden,cell_state)\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "  #generating the decode inputs\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['\\t']], 0)\n",
        "\n",
        "  #storing the attention weights\n",
        "  att_w=[]\n",
        "\n",
        "  #calculating the predictions\n",
        "  for t in range(max_length_targ):\n",
        "    #if cell is GRU or RNN\n",
        "    if rnn_type!='LSTM':\n",
        "      predictions, dec_hidden, attention_weights = decoder(dec_input,dec_hidden,enc_out)\n",
        "    #if cell is LSTM\n",
        "    elif rnn_type=='LSTM':\n",
        "      predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out, enc_cell_state)\n",
        "      dec_hidden=dec_hidden[0]\n",
        "\n",
        "    # storing the attention weights for plotting latter\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    att_w.append(attention_weights.numpy()[0:len(input_word)])\n",
        "\n",
        "\n",
        "    #predicted id\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    #predicted word\n",
        "    predicted_word += targ_lang.index_word[predicted_id]\n",
        "\n",
        "    #in case of last character\n",
        "    if targ_lang.index_word[predicted_id] == '\\n':\n",
        "      return predicted_word, input_word, attention_plot,att_w\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #finally return the predicted word, input word, attention plot and the attention weight\n",
        "  return predicted_word, input_word, attention_plot,att_w"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validation Function\n",
        "This function evaluates the model's prediction accuracy on a dataset by comparing predicted outputs to target sequences. It supports saving predictions into success and failure files when validating test data, and returns the overall accuracy of predictions."
      ],
      "metadata": {
        "id": "wuOoeU7I-T_H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DVHrrxwt9Ro5"
      },
      "outputs": [],
      "source": [
        "def _setup_prediction_directories(file_path, folder_name):\n",
        "    \"\"\"Helper function to create directory structure for test predictions\"\"\"\n",
        "    predictions_dir = os.path.join(os.getcwd(), \"predictions_attention\")\n",
        "    target_folder = os.path.join(predictions_dir, str(folder_name))\n",
        "\n",
        "    # Clean existing folder if it exists\n",
        "    if os.path.exists(target_folder):\n",
        "        shutil.rmtree(target_folder)\n",
        "\n",
        "    # Create directory structure\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.mkdir(predictions_dir)\n",
        "    os.mkdir(target_folder)\n",
        "\n",
        "    return target_folder\n",
        "\n",
        "def _initialize_output_files(folder_path):\n",
        "    \"\"\"Helper function to create and open output files for predictions\"\"\"\n",
        "    success_filepath = os.path.join(folder_path, \"success.txt\")\n",
        "    failure_filepath = os.path.join(folder_path, \"failure.txt\")\n",
        "\n",
        "    success_handle = open(success_filepath, \"w\", encoding='utf-8', errors='ignore')\n",
        "    failure_handle = open(failure_filepath, \"w\", encoding='utf-8', errors='ignore')\n",
        "\n",
        "    return success_handle, failure_handle\n",
        "\n",
        "def _process_single_prediction(input_text, target_text, rnn_model_type):\n",
        "    \"\"\"Helper function to generate prediction for a single input\"\"\"\n",
        "    predicted_text, processed_input, attention_data, attention_weights = inference_model(input_text, rnn_model_type)\n",
        "\n",
        "    # Format record for output\n",
        "    formatted_record = f\"{processed_input.strip()} {target_text.strip()} {predicted_text[:-1].strip()}\\n\"\n",
        "\n",
        "    return predicted_text, formatted_record\n",
        "\n",
        "def _evaluate_prediction_accuracy(target_text, predicted_text):\n",
        "    \"\"\"Helper function to check if prediction matches target\"\"\"\n",
        "    # Handle formatting differences (target has leading tab, both have trailing newline)\n",
        "    normalized_target = target_text[1:]  # Remove leading tab\n",
        "    return normalized_target == predicted_text\n",
        "\n",
        "def _write_prediction_result(record, is_correct, success_file, failure_file):\n",
        "    \"\"\"Helper function to write prediction results to appropriate file\"\"\"\n",
        "    if is_correct and success_file:\n",
        "        success_file.write(record)\n",
        "    elif not is_correct and failure_file:\n",
        "        failure_file.write(record)\n",
        "\n",
        "def _cleanup_files(file_handles):\n",
        "    \"\"\"Helper function to safely close file handles\"\"\"\n",
        "    for handle in file_handles:\n",
        "        if handle:\n",
        "            handle.close()\n",
        "\n",
        "def validate(path_to_file, folder_name):\n",
        "    \"\"\"\n",
        "    Main validation function that computes accuracy on validation/test data\n",
        "    and optionally saves prediction results to files\n",
        "    \"\"\"\n",
        "    # Determine if we need to save predictions based on file path\n",
        "    should_save_predictions = \"test\" in path_to_file\n",
        "    success_file_handle = None\n",
        "    failure_file_handle = None\n",
        "\n",
        "    # Setup output directories and files if needed\n",
        "    if should_save_predictions:\n",
        "        output_folder = _setup_prediction_directories(path_to_file, folder_name)\n",
        "        success_file_handle, failure_file_handle = _initialize_output_files(output_folder)\n",
        "\n",
        "    # Load dataset for evaluation\n",
        "    target_sequences, input_sequences = create_dataset(path_to_file)\n",
        "\n",
        "    # Initialize accuracy counter\n",
        "    correct_predictions = 0\n",
        "    total_samples = len(input_sequences)\n",
        "\n",
        "    # Process each input-target pair\n",
        "    for idx in range(total_samples):\n",
        "        current_input = input_sequences[idx]\n",
        "        current_target = target_sequences[idx]\n",
        "\n",
        "        # Generate prediction\n",
        "        prediction_result, output_record = _process_single_prediction(\n",
        "            current_input, current_target, rnn_type\n",
        "        )\n",
        "\n",
        "        # Check accuracy\n",
        "        is_prediction_correct = _evaluate_prediction_accuracy(current_target, prediction_result)\n",
        "\n",
        "        # Update counter\n",
        "        if is_prediction_correct:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        # Save results if required\n",
        "        if should_save_predictions:\n",
        "            _write_prediction_result(\n",
        "                output_record, is_prediction_correct,\n",
        "                success_file_handle, failure_file_handle\n",
        "            )\n",
        "\n",
        "    # Cleanup resources\n",
        "    if should_save_predictions:\n",
        "        _cleanup_files([success_file_handle, failure_file_handle])\n",
        "\n",
        "    # Calculate and return accuracy\n",
        "    accuracy_score = correct_predictions / total_samples\n",
        "    return accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Attention Plotting Function\n",
        "This function visualizes the attention weights between input and predicted words using a heatmap. It sets up labels with Hindi font support and saves the plot, aiding in interpreting which input characters the model focused on during each decoding step."
      ],
      "metadata": {
        "id": "o8hhBXYG-eLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MoLXeHzI9VBr"
      },
      "outputs": [],
      "source": [
        "def plot_attention(attention, input_word, predicted_word, file_name):\n",
        "    # Set up the font for displaying Hindi characters\n",
        "    hindi_font_path = os.path.join(os.getcwd(), \"Nirmala.ttf\")\n",
        "    hindi_font = FontProperties(fname=hindi_font_path)\n",
        "\n",
        "    # Create a figure for the heatmap\n",
        "    fig = plt.figure(figsize=(3, 3))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    # Show attention matrix\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    # Set tick labels\n",
        "    _set_axis_labels(ax, input_word, predicted_word, hindi_font)\n",
        "\n",
        "    # Save and display the attention plot\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_name)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def _set_axis_labels(ax, input_text, output_text, font):\n",
        "    font_opts = {'fontsize': 14}\n",
        "\n",
        "    # Set x-axis labels\n",
        "    x_labels = ['']\n",
        "    for ch in input_text:\n",
        "        x_labels.append(ch)\n",
        "    ax.set_xticklabels(x_labels, fontdict=font_opts)\n",
        "\n",
        "    # Set y-axis labels with Hindi font\n",
        "    y_labels = ['']\n",
        "    for ch in output_text:\n",
        "        y_labels.append(ch)\n",
        "    ax.set_yticklabels(y_labels, fontdict=font_opts, fontproperties=font)\n",
        "\n",
        "    # Set tick interval to 1 for clarity\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oJHKHIcC9ijI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Geting the connectivity html file.\n",
        "\"\"\"\n",
        "\n",
        "def cstr(s, color='black'):\n",
        "    \"\"\"\n",
        "    Create HTML text element with background color styling.\n",
        "\n",
        "    Args:\n",
        "        s: Text content to style\n",
        "        color: Background color for the text\n",
        "\n",
        "    Returns:\n",
        "        HTML formatted string with styling\n",
        "    \"\"\"\n",
        "    if s.strip() == '':\n",
        "        # Handle whitespace characters with special padding\n",
        "        return f'<span style=\"color:#000000;padding-left:10px;background-color:{color};\">&nbsp;</span>'\n",
        "    else:\n",
        "        # Regular text with background color\n",
        "        return f'<span style=\"color:#000000;background-color:{color};\">{s}&nbsp;</span>'\n",
        "\n",
        "\n",
        "def print_color(t):\n",
        "    \"\"\"\n",
        "    Display colored HTML text from tuples of (text, color) pairs.\n",
        "\n",
        "    Args:\n",
        "        t: List of tuples containing (text, color) pairs\n",
        "    \"\"\"\n",
        "    # Combine all HTML elements into single string\n",
        "    html_content = ''.join([cstr(text_item, color=color_item) for text_item, color_item in t])\n",
        "\n",
        "    # Display the HTML (assumes display and html_print are available in environment)\n",
        "    display(html_print(html_content))\n",
        "\n",
        "\n",
        "def get_clr(value):\n",
        "    \"\"\"\n",
        "    Map attention weight values to appropriate background colors.\n",
        "    Uses gradient from blue (low attention) to red (high attention).\n",
        "\n",
        "    Args:\n",
        "        value: Attention weight value (expected range 0-1)\n",
        "\n",
        "    Returns:\n",
        "        Hex color code string\n",
        "    \"\"\"\n",
        "    # Color palette: blue tones for low values, red tones for high values\n",
        "    color_palette = [\n",
        "        '#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
        "        '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "        '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "        '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e'\n",
        "    ]\n",
        "\n",
        "    # Scale value to color index (0-19)\n",
        "    color_index = min(int((value * 100) / 5), len(color_palette) - 1)\n",
        "    return color_palette[color_index]\n",
        "\n",
        "\n",
        "def visualize(input_word, output_word, att_w):\n",
        "    \"\"\"\n",
        "    Create visualization of attention weights between input and output sequences.\n",
        "\n",
        "    Args:\n",
        "        input_word: List of input tokens/characters\n",
        "        output_word: List of output tokens/characters\n",
        "        att_w: 2D array of attention weights [output_len x input_len]\n",
        "    \"\"\"\n",
        "    # Process each output character\n",
        "    for output_idx in range(len(output_word)):\n",
        "        print(f\"\\nOutput character: {output_word[output_idx]}\\n\")\n",
        "\n",
        "        # Create color-coded representation for current output character\n",
        "        colored_tokens = []\n",
        "\n",
        "        # Map each input character to its attention weight color\n",
        "        for input_idx in range(len(att_w[output_idx])):\n",
        "            attention_weight = att_w[output_idx][input_idx]\n",
        "            background_color = get_clr(attention_weight)\n",
        "\n",
        "            # Create tuple of (character, color) for visualization\n",
        "            token_color_pair = (input_word[input_idx], background_color)\n",
        "            colored_tokens.append(token_color_pair)\n",
        "\n",
        "        # Display the colored sequence\n",
        "        print_color(colored_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QvyqHnYQ9ka_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Code for connectivity visualisation.\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "def get_shade_color(value):\n",
        "    \"\"\"\n",
        "    Convert attention weight value to corresponding green shade color.\n",
        "    Higher values get darker green colors to indicate stronger connections.\n",
        "\n",
        "    Args:\n",
        "        value: Attention weight value (0-1 range)\n",
        "\n",
        "    Returns:\n",
        "        Hex color code string representing green shade\n",
        "    \"\"\"\n",
        "    # Green gradient palette from light to dark\n",
        "    green_shades = [\n",
        "        '#00fa00', '#00f500', '#00eb00', '#00e000', '#00db00',\n",
        "        '#00d100', '#00c700', '#00c200', '#00b800', '#00ad00',\n",
        "        '#00a800', '#009e00', '#009400', '#008f00', '#008500',\n",
        "        '#007500', '#007000', '#006600', '#006100', '#005c00',\n",
        "        '#005200', '#004d00', '#004700', '#003d00', '#003800',\n",
        "        '#003300', '#002900', '#002400', '#001f00', '#001400'\n",
        "    ]\n",
        "\n",
        "    # Map value to color index\n",
        "    shade_index = min(int((value * 100) / 5), len(green_shades) - 1)\n",
        "    return green_shades[shade_index]\n",
        "\n",
        "\n",
        "def create_file(text_colors, input_word, output_word, file_path=None):\n",
        "    \"\"\"\n",
        "    Generate interactive HTML file for connectivity visualization.\n",
        "\n",
        "    Args:\n",
        "        text_colors: 3D list of color codes for each word pair\n",
        "        input_word: List of input word sequences\n",
        "        output_word: List of output word sequences\n",
        "        file_path: Directory path for saving HTML file\n",
        "    \"\"\"\n",
        "    if file_path is None:\n",
        "        file_path = os.getcwd()\n",
        "\n",
        "    # Initialize HTML document structure\n",
        "    html_content = build_html_header()\n",
        "\n",
        "    # Add JavaScript color data\n",
        "    html_content += generate_color_array(text_colors, output_word)\n",
        "\n",
        "    # Add interactive JavaScript handlers\n",
        "    html_content += generate_mouseover_handlers(input_word, output_word)\n",
        "\n",
        "    # Close JavaScript section and add body\n",
        "    html_content += close_script_and_add_body()\n",
        "\n",
        "    # Generate HTML content for each sequence\n",
        "    for sequence_idx in range(3):\n",
        "        html_content += create_sequence_section(\n",
        "            sequence_idx, input_word[sequence_idx], output_word[sequence_idx]\n",
        "        )\n",
        "\n",
        "        if sequence_idx < 2:\n",
        "            html_content += add_section_separator()\n",
        "\n",
        "    # Close HTML document\n",
        "    html_content += close_html_document()\n",
        "\n",
        "    # Write to file\n",
        "    output_file = os.path.join(file_path, \"connectivity.html\")\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html_content)\n",
        "\n",
        "\n",
        "def build_html_header():\n",
        "    \"\"\"Build the HTML document header with jQuery.\"\"\"\n",
        "    return '''<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script>\n",
        "    <script>\n",
        "        $(document).ready(function(){\n",
        "        var col = ['''\n",
        "\n",
        "\n",
        "def generate_color_array(text_colors, output_word):\n",
        "    \"\"\"Generate JavaScript color array from text_colors data.\"\"\"\n",
        "    color_array_content = \"\"\n",
        "\n",
        "    for seq_idx in range(3):\n",
        "        for word_idx in range(len(output_word[seq_idx])):\n",
        "            color_array_content += \"[\"\n",
        "\n",
        "            # Add colors for each character\n",
        "            colors_for_word = text_colors[seq_idx][word_idx]\n",
        "            for color_idx, color in enumerate(colors_for_word):\n",
        "                color_array_content += f'\"{color}\"'\n",
        "                if color_idx < len(colors_for_word) - 1:\n",
        "                    color_array_content += \",\"\n",
        "\n",
        "            color_array_content += \"],\"\n",
        "\n",
        "    # Remove trailing comma and close array\n",
        "    return color_array_content.rstrip(\",\") + \"];\\n\"\n",
        "\n",
        "\n",
        "def generate_mouseover_handlers(input_word, output_word):\n",
        "    \"\"\"Generate JavaScript mouseover and mouseout event handlers.\"\"\"\n",
        "    handler_content = \"\"\n",
        "\n",
        "    for seq_idx in range(3):\n",
        "        for output_idx in range(len(output_word[seq_idx])):\n",
        "            # Create mouseover handler\n",
        "            handler_content += f'$(\".h{seq_idx}{output_idx}\").mouseover(function(){{\\n'\n",
        "\n",
        "            for input_idx in range(len(input_word[seq_idx])):\n",
        "                color_ref = f\"col[{output_idx}][{input_idx}]\"\n",
        "                handler_content += f'$(\".t{seq_idx}{input_idx}\").css(\"background-color\", {color_ref});\\n'\n",
        "\n",
        "            handler_content += \"});\\n\"\n",
        "\n",
        "            # Create mouseout handler (reset all backgrounds)\n",
        "            handler_content += f'$(\".h{seq_idx}{output_idx}\").mouseout(function(){{\\n'\n",
        "\n",
        "            for reset_seq in range(3):\n",
        "                for reset_input in range(len(input_word[reset_seq])):\n",
        "                    handler_content += f'$(\".t{reset_seq}{reset_input}\").css(\"background-color\", \"#ffff99\");\\n'\n",
        "\n",
        "            handler_content += \"});\\n\"\n",
        "\n",
        "    return handler_content\n",
        "\n",
        "\n",
        "def close_script_and_add_body():\n",
        "    \"\"\"Close JavaScript section and start HTML body.\"\"\"\n",
        "    return '''});\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Connectivity:</h1>\n",
        "    <p>The connection strength between the target for the selected character and the input characters is highlighted in green (reset). Hover over the text to change the selected character.</p>\n",
        "    <div style=\"background-color:#ffff99;color:black;padding:2%; margin:4%;\">\n",
        "    <p>\n",
        "    <div>Output:</div>\n",
        "    <div style='display:flex; border: 2px solid #d0cccc; padding: 8px; margin: 8px;'>'''\n",
        "\n",
        "\n",
        "def create_sequence_section(seq_idx, input_sequence, output_sequence):\n",
        "    \"\"\"Create HTML section for one input/output sequence pair.\"\"\"\n",
        "    section_content = \"\"\n",
        "\n",
        "    # Add output characters\n",
        "    for char_idx, char in enumerate(output_sequence):\n",
        "        section_content += f'\\n\\t<div class=\"h{seq_idx}{char_idx}\">{char}</div>'\n",
        "\n",
        "    section_content += '''</div>\n",
        "    </p>\n",
        "    <p>\n",
        "    <div>Input:</div>\n",
        "    <div style='display:flex; border: 2px solid #d0cccc; padding: 8px; margin: 8px;'>'''\n",
        "\n",
        "    # Add input characters\n",
        "    for char_idx, char in enumerate(input_sequence):\n",
        "        section_content += f'\\n\\t<div class=\"t{seq_idx}{char_idx}\">{char}</div>'\n",
        "\n",
        "    return section_content\n",
        "\n",
        "\n",
        "def add_section_separator():\n",
        "    \"\"\"Add separator between sections.\"\"\"\n",
        "    return '''</div></p></div><p></p></div>\n",
        "    <div style=\"background-color:#ffff99;color:black;padding:2%; margin:4%;\">\n",
        "    <div>Output:</div>\n",
        "    <div style='display:flex; border: 2px solid #d0cccc; padding: 8px; margin: 8px;'>'''\n",
        "\n",
        "\n",
        "def close_html_document():\n",
        "    \"\"\"Close the HTML document structure.\"\"\"\n",
        "    return '''\n",
        "        </div>\n",
        "        </p>\n",
        "        </div>\n",
        "        </body>\n",
        "</html>'''\n",
        "\n",
        "\n",
        "def connectivity(input_words, rnn_type, file_path):\n",
        "    \"\"\"\n",
        "    Main function to generate connectivity visualization HTML file.\n",
        "\n",
        "    Args:\n",
        "        input_words: List of 3 input word sequences\n",
        "        rnn_type: Type of RNN model to use for inference\n",
        "        file_path: Directory path for saving output file\n",
        "    \"\"\"\n",
        "    # Initialize data containers\n",
        "    processed_colors = []\n",
        "    processed_input_words = []\n",
        "    processed_output_words = []\n",
        "\n",
        "    # Process each of the 3 input sequences\n",
        "    for sequence_idx in range(3):\n",
        "        # Get model predictions and attention weights\n",
        "        predicted_output, processed_input, _, attention_matrix = inference_model(\n",
        "            input_words[sequence_idx], rnn_type\n",
        "        )\n",
        "\n",
        "        # Convert attention weights to color codes\n",
        "        sequence_colors = []\n",
        "        for output_pos in range(len(predicted_output)):\n",
        "            color_row = []\n",
        "            for input_pos in range(len(attention_matrix[output_pos])):\n",
        "                attention_value = attention_matrix[output_pos][input_pos]\n",
        "                color_code = get_shade_color(attention_value)\n",
        "                color_row.append(color_code)\n",
        "            sequence_colors.append(color_row)\n",
        "\n",
        "        # Store processed data\n",
        "        processed_colors.append(sequence_colors)\n",
        "        processed_input_words.append(processed_input)\n",
        "        processed_output_words.append(predicted_output)\n",
        "\n",
        "    # Generate HTML visualization file\n",
        "    create_file(processed_colors, processed_input_words, processed_output_words, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "scx1WsVh9mEV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def transliterate(input_word, rnn_type, file_name=None, visual_flag=True):\n",
        "    # Set default file path if none is provided\n",
        "    if file_name is None:\n",
        "        file_name = os.path.join(os.getcwd(), \"attention_heatmap.png\")\n",
        "\n",
        "    # Perform inference to get outputs\n",
        "    predicted, cleaned_input, att_matrix, attention_weights_list = _run_inference(input_word, rnn_type)\n",
        "\n",
        "    # Display the results\n",
        "    _display_transliteration(cleaned_input, predicted)\n",
        "\n",
        "    # Resize the attention matrix to match actual lengths\n",
        "    att_matrix = att_matrix[:len(predicted), :len(cleaned_input)]\n",
        "\n",
        "    # Generate and save the attention heatmap\n",
        "    plot_attention(att_matrix, cleaned_input, predicted, file_name)\n",
        "\n",
        "    # Optionally visualize attention weights step by step\n",
        "    if visual_flag:\n",
        "        visualize(cleaned_input, predicted, attention_weights_list)\n",
        "\n",
        "\n",
        "\n",
        "def _run_inference(input_text, rnn_type):\n",
        "    predicted_output, formatted_input, att_plot, attention_weights = inference_model(input_text, rnn_type)\n",
        "    return predicted_output, formatted_input, att_plot, attention_weights\n",
        "\n",
        "\n",
        "def _display_transliteration(source, prediction):\n",
        "    print(\"\\nInput:\", source)\n",
        "    print(\"Predicted transliteration:\", prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nxsCx9iU9n6m"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_inputs(rnn_type, n_test_samples=10):\n",
        "    # Load test input-target word pairs\n",
        "    target_list, input_list = create_dataset(test_file_path)\n",
        "\n",
        "    # Loop through requested number of test samples\n",
        "    count = 0\n",
        "    while count < n_test_samples:\n",
        "        random_idx = _get_random_index(len(input_list))\n",
        "        test_input = input_list[random_idx]\n",
        "        save_path = _build_output_path(test_input)\n",
        "\n",
        "        # First prediction with visualization\n",
        "        if count == 0:\n",
        "            transliterate(test_input[1:-1], rnn_type, save_path, visual_flag=True)\n",
        "        else:\n",
        "            transliterate(test_input[1:-1], rnn_type, save_path, visual_flag=False)\n",
        "\n",
        "        count += 1\n",
        "\n",
        "\n",
        "def _get_random_index(max_val):\n",
        "    return random.randint(0, max_val - 1)\n",
        "\n",
        "\n",
        "def _build_output_path(input_str):\n",
        "    folder_path = os.path.join(os.getcwd(), \"predictions_attention\", str(run_name))\n",
        "    file_name = input_str + \".png\"\n",
        "    return os.path.join(folder_path, file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zRKjcUDR-r1F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4469018a-91f9-42a1-ef96-916205962eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m034\u001b[0m (\u001b[33mcs24m034-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: v6y1zvai\n",
            "Sweep URL: https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/sweeps/v6y1zvai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 65vs3am1 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbs: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: LSTM\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250522_220007-65vs3am1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/runs/65vs3am1' target=\"_blank\">divine-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/sweeps/v6y1zvai' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/sweeps/v6y1zvai</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/sweeps/v6y1zvai' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/sweeps/v6y1zvai</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/runs/65vs3am1' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/DA6401_Assignment3_attention/runs/65vs3am1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected RNN Architecture: LSTM\n",
            "Encoder output shape: (batch size, sequence length, units) (64, 22, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
            "Encoder Cell state shape: (batch size, units) (64, 1024)\n",
            "Decoder output shape: (batch_size, vocab size) (64, 65)\n",
            "Epoch 1 Loss 0.3785\n",
            "Time taken for 1 epoch 217.93 sec\n",
            "\n",
            "Epoch 2 Loss 0.1354\n",
            "Time taken for 1 epoch 203.81 sec\n",
            "\n",
            "Epoch 3 Loss 0.1005\n",
            "Time taken for 1 epoch 202.98 sec\n",
            "\n",
            "Epoch 4 Loss 0.0770\n",
            "Time taken for 1 epoch 203.82 sec\n",
            "\n",
            "Epoch 5 Loss 0.0666\n",
            "Time taken for 1 epoch 202.91 sec\n",
            "\n",
            "Epoch 6 Loss 0.0500\n",
            "Time taken for 1 epoch 203.60 sec\n",
            "\n",
            "Epoch 7 Loss 0.0410\n",
            "Time taken for 1 epoch 202.92 sec\n",
            "\n",
            "Epoch 8 Loss 0.0334\n",
            "Time taken for 1 epoch 203.51 sec\n",
            "\n",
            "Epoch 9 Loss 0.0330\n",
            "Time taken for 1 epoch 202.83 sec\n",
            "\n",
            "Epoch 10 Loss 0.0293\n",
            "Time taken for 1 epoch 203.57 sec\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Sweep configuration for hyper parameter tuning\n",
        "'''\n",
        "!pip install wandb --upgrade\n",
        "import wandb\n",
        "# !wandb login\n",
        "wandb.login(key=\"7f46816d45e3df192c3053bab59032e9d710fef4\")\n",
        "sweep_config = {\n",
        "    \"name\": \"Bayesian Sweep without attention\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "\n",
        "        \"rnn_type\": {\"values\": [\"LSTM\"]},  #RNN, GRU\n",
        "\n",
        "        \"embed\": {\"values\": [256,512]},\n",
        "\n",
        "        \"latent\": {\"values\": [512,1024]},\n",
        "\n",
        "        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "\n",
        "        \"epochs\": {\"values\": [20]},\n",
        "\n",
        "        \"bs\": {\"values\": [64]},\n",
        "\n",
        "\n",
        "    },\n",
        "  }\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment3_attention\", entity=\"cs24m034-indian-institute-of-technology-madras\")\n",
        "\n",
        "wandb.agent(sweep_id, train, count = 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '''\n",
        "# manual training for the best parameter model\n",
        "# '''\n",
        "# manual_train()"
      ],
      "metadata": {
        "id": "Q3qXCUCWPPRI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZfLraCi9tER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "67f172f9-3676-40b5-fa34-c8d872d25849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/predictions_attention/ (stored 0%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/ (stored 0%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Ibolane^J.png (deflated 11%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Ipharmacy^J.png (deflated 8%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/connectivity.html (deflated 96%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Ibhagane^J.png (deflated 12%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Ijoddta^J.png (deflated 11%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Inikalegi^J.png (deflated 8%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Imahanatam^J.png (deflated 10%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Iagr^J.png (deflated 13%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Ikatthaii^J.png (deflated 9%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/success.txt (deflated 79%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/failure.txt (deflated 76%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Imamuli^J.png (deflated 12%)\n",
            "  adding: content/predictions_attention/_epochs_20_rnn_type_LSTM_bs_64_embed_512_latent_1024_dropout_0.2/^Ivishahin^J.png (deflated 9%)\n",
            "  adding: content/training_checkpoints/ (stored 0%)\n",
            "  adding: content/training_checkpoints/ckpt-7.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-5.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-10.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-9.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-1.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-4.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-9.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-8.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/checkpoint (deflated 38%)\n",
            "  adding: content/training_checkpoints/ckpt-8.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-10.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-7.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-4.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-3.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-2.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-6.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-3.index (deflated 69%)\n",
            "  adding: content/training_checkpoints/ckpt-2.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-6.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-1.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_checkpoints/ckpt-5.index (deflated 69%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_61960e6f-795e-4675-81cd-591bab762e1c\", \"predictions_attention.zip\", 84504)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_72c2bca5-bde4-43d0-b21f-28fd7c401137\", \"training_checkpoints.zip\", 2119938640)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Download a copy of the predictions_attention and training_checkpoints folder.\n",
        "!zip -r /content/predictions_attention.zip /content/predictions_attention\n",
        "!zip -r /content/training_checkpoints.zip /content/training_checkpoints\n",
        "from google.colab import files\n",
        "files.download(\"/content/predictions_attention.zip\")\n",
        "files.download(\"/content/training_checkpoints.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdPIgZbocyn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}